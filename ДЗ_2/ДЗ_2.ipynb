{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0593b0c0",
   "metadata": {},
   "source": [
    "Мария Сухарева"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6147dc8",
   "metadata": {},
   "source": [
    "В моем тексте я выделила несколько сложных моментов. Мой корпус начинается со слова \"собес\", что является аббревиатурой, я его разметила как PROPN по выбранному тегсету, но из-за того, что в русском языке это слово уже не пишут прописными буквами, некоторые теггеры разметили его как просто существительное. Далее я включила два разных слова с дефисом внутри, чтобы посмотреть, как разные теггеры будут их делить, слово \"из-за\" делить не надо было, а \"диван-кровать\" - надо, один теггер делил все, другой - ничего, но один все-таки справился. Также я включила в свой корпус такое словосочетание с омонимией, как \"маша руками\", где \"маша\" нужно разметить как глагол, но большинство теггеров его размечают, как имя собственное. Еще я включила два непростых слова \"меццо\" и \"сопрано\", не все теггеры разметили это как существительные. Кроме того, можно встретить три субстантивированных существительных - \"скорые\", \"раненые\" и \"погибшие\", не все теггеры разметили их как существительные. Еще один интересный момент - у меня было слово \"вжжик\", которое надо разметить как INTJ, но большинство теггеров размечают его как-то по-другому. Еще в моем корпусе есть слово \"Танину\", что хотелось бы разметить как ADJ, потому что это все-таки притяжательное прилагательное, но некоторые теггеры размечали его как имя собственное. И также было несколько моментов, где можно было перепутать наречие это или краткое прилагательное и, наоборот, с чем тоже справились не все теггеры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883c1b8",
   "metadata": {},
   "source": [
    "В моей разметке я использовала тегсет Universal POS tags, потому что это один из самых распространенных тегсетов, его используют многие различные POS теггеры. В моем корпусе я не ставила задачу различать разные виды существительных (просто существительные и местоимения-существительные, например), прилагательных (числительное-прилагательное, местоимение-прилагательное, например) и так далее, а мне было более интересно помотреть на то, как теггеры размечают глобальные части речи, если можно так сказать, то есть не вводить что-то смешанное, а смотреть на все более раздельно. Кроме того, в Universal POS tags есть различие между сочинительными и подчинительными союзами (CCONJ и SCONJ), что как раз хорошо подходит для русского языка. Я не стала выделять отдельно причастия и деепричастия, потому что это можно посмотреть в дополнительных признаках, и на самом деле многие теггеры используют тегсеты, где это отдельно не выделяется. Еще мне показалось хорошим то, что в Universal POS tags отдельно выделяется AUX, что хорошо для русского \"быть\" в некоторых конструкциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5fcfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#загружаю свой размеченный корпус и делю его на два списка: один с токенами, другой с POS тегами\n",
    "import pandas as pd\n",
    "\n",
    "text = open('changedtime.txt', encoding='utf-8').read()\n",
    "\n",
    "token_mine = []\n",
    "pos_mine = []\n",
    "\n",
    "df = pd.read_excel('changedtime_tags.xlsx')\n",
    "for i in range(df.shape[0]):\n",
    "    token_mine.append(df.iloc[i]['token'])\n",
    "    pos_mine.append(df.iloc[i]['pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce54a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#прогоняю текст через первый теггер, результат также делю на два списка\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "doc = Doc(text)\n",
    "doc.segment(segmenter)\n",
    "doc.tag_morph(morph_tagger)\n",
    "\n",
    "token_natasha = []\n",
    "pos_natasha = []\n",
    "\n",
    "for _ in doc.tokens:\n",
    "    token_natasha.append(_.text)\n",
    "    pos_natasha.append(_.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945f06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#аналогично для второго и третьего\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ru_core_news_md')\n",
    "document = nlp(text)\n",
    "\n",
    "token_spacy = []\n",
    "pos_spacy = []\n",
    "\n",
    "for token in document:\n",
    "    token_spacy.append(str(token))\n",
    "    pos_spacy.append(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21adec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 22:43:12 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7838b3dc372b49d4835bf1d591873600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 22:43:13 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| pos       | syntagrus |\n",
      "=========================\n",
      "\n",
      "2022-10-11 22:43:13 INFO: Use device: cpu\n",
      "2022-10-11 22:43:13 INFO: Loading: tokenize\n",
      "2022-10-11 22:43:13 INFO: Loading: pos\n",
      "2022-10-11 22:43:13 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "nlps = stanza.Pipeline(lang='ru', processors='tokenize,pos')\n",
    "doc = nlps(text)\n",
    "\n",
    "token_stanza = []\n",
    "pos_stanza = []\n",
    "\n",
    "for sent in doc.sentences:\n",
    "    for word in sent.words:\n",
    "        token_stanza.append(word.text)\n",
    "        pos_stanza.append(word.upos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0aca51",
   "metadata": {},
   "source": [
    "Мне не понадобилась функция-конвертор для POS тегов, потому что все выбранные мной библиотеки используют тегсет Universal POS tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d16380",
   "metadata": {},
   "source": [
    "Далее идет моя функция, которая записывает в результаты единицу, если POS теги совпали, и ноль, если нет. В этой функции я иду по спискам токенов - моего эталона и сравниваемого теггера. Возможно, списки в данном случае - не очень хорошо, можно придумать более эффективный способ, но это все, что пришло мне в голову. Я думала использовать словари, но тогда не понятно, что брать за ключи, так как токены брать нельзя, они могут повторяться. Далее я обращаюсь по индексу к списку POS тегов, индексы как раз будут равны, если токены совпадают. Я ввела дополнительные смещения индекса bias, так как не все теггеры правильно делят слова с дефисами. Там, где я проверяю, равен ли токен конкретно \"из-за\" или \"диван-кровати\", хорошо бы заменить на что-то более общее, но я не смогла придумать, как это можно развести получше, а так как мой корпус небольшой, и я знала, что там всего два таких конкретных слова, то я просто проверяла по токену, что, конечно, к сожалению, совсем неэффективно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae9adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(token, pos, token_mine, pos_mine):\n",
    "    \n",
    "    bias_mine = 0\n",
    "    bias = 0\n",
    "    results = []\n",
    "    \n",
    "    if token > token_mine:\n",
    "        tokens = token\n",
    "    else:\n",
    "        tokens = token_mine\n",
    "        \n",
    "    for i in range(len(tokens)):\n",
    "        if token[i+bias] == token_mine[i+bias_mine]:\n",
    "            if pos[i+bias] == pos_mine[i+bias_mine]:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "        elif token_mine[i+bias_mine] == 'из-за':\n",
    "            results.append(0)\n",
    "            bias += 2\n",
    "        elif token[i+bias] == 'диван-кровати':\n",
    "            results.append(0)\n",
    "            bias_mine += 2\n",
    "        else:\n",
    "            results.append(0)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f7a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#оцениваю accuracy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b66a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9007633587786259"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#для natasha\n",
    "results_natasha = compare(token_natasha, pos_natasha, token_mine, pos_mine)\n",
    "#для моих результатов я создаю список из единичек длиной, как список оцениваемого теггера, что скорее всего тоже не совсем эффективно, но я не смогла придумать лучше\n",
    "results_mine = []\n",
    "\n",
    "for i in range(len(results_natasha)):\n",
    "    results_mine.append(1)\n",
    "\n",
    "accuracy_natasha = accuracy_score(results_natasha, results_mine)\n",
    "accuracy_natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b6dca3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8977272727272727"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#для spacy\n",
    "results_spacy = compare(token_spacy, pos_spacy, token_mine, pos_mine)\n",
    "\n",
    "results_mine = []\n",
    "\n",
    "for i in range(len(results_spacy)):\n",
    "    results_mine.append(1)\n",
    "\n",
    "accuracy_spacy = accuracy_score(results_spacy, results_mine)\n",
    "accuracy_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ef6d51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242424242424242"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#для stanza\n",
    "results_stanza = compare(token_stanza, pos_stanza, token_mine, pos_mine)\n",
    "\n",
    "results_mine = []\n",
    "\n",
    "for i in range(len(results_stanza)):\n",
    "    results_mine.append(1)\n",
    "\n",
    "accuracy_stanza = accuracy_score(results_stanza, results_mine)\n",
    "accuracy_stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678a382",
   "metadata": {},
   "source": [
    "Лучшим оказался stanza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d3049",
   "metadata": {},
   "source": [
    "Далее я создаю функцию (chunker) для пяти типов n-грамм:\n",
    "1. ADJ + NOUN - достаточно очевидная биграмма для определения положительных и отрицательных отзывов, потому что в отзывах часто встречается описание какого-то объекта положительными или отрицательными прилагательными (хороший бассейн, плхая кровать)\n",
    "2. ADV + VERB - такие сочетания тоже достаточно часто встречаются в отзывах, особенно, если помнить, что в stanza VERB может быть не только просто глаголом, но и еще причастием и деепричастием (плохо/хорошо сделан)\n",
    "4. \"не\" + VERB - может встретиться в отрицательных отзывах (не работает, не положили)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd33a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(pos, token):\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(len(pos)):\n",
    "        if pos[i] == 'ADJ' and pos[i+1] == 'NOUN':\n",
    "            chunks.append(token[i]+' '+token[i+1])\n",
    "        if pos[i] == 'ADV' and pos[i+1] == 'VERB':\n",
    "            chunks.append(token[i]+' '+token[i+1])\n",
    "        if token[i] == 'не' and pos[i+1] == 'VERB':\n",
    "            chunks.append(token[i]+' '+token[i+1])\n",
    "            \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd79384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
